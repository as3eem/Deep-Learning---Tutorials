{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading tokenizer: laptop_tokenizer.dat\n",
      "loading embedding_matrix: 300_laptop_embedding_matrix.dat\n",
      "loading model ian ...\n",
      "IAN(\n",
      "  (embed): Embedding(3600, 300)\n",
      "  (lstm_context): DynamicLSTM(\n",
      "    (RNN): LSTM(300, 300, batch_first=True)\n",
      "  )\n",
      "  (lstm_aspect): DynamicLSTM(\n",
      "    (RNN): LSTM(300, 300, batch_first=True)\n",
      "  )\n",
      "  (attention_aspect): Attention(\n",
      "    (w_k): Linear(in_features=300, out_features=300, bias=True)\n",
      "    (w_q): Linear(in_features=300, out_features=300, bias=True)\n",
      "    (proj): Linear(in_features=300, out_features=300, bias=True)\n",
      "    (dropout): Dropout(p=0, inplace=False)\n",
      "  )\n",
      "  (attention_context): Attention(\n",
      "    (w_k): Linear(in_features=300, out_features=300, bias=True)\n",
      "    (w_q): Linear(in_features=300, out_features=300, bias=True)\n",
      "    (proj): Linear(in_features=300, out_features=300, bias=True)\n",
      "    (dropout): Dropout(p=0, inplace=False)\n",
      "  )\n",
      "  (dense): Linear(in_features=600, out_features=3, bias=True)\n",
      ")\n",
      "[1]\n",
      "tensor([0.0236, 0.0394, 0.0587, 0.2149, 0.6634])\n",
      "[0]\n",
      "tensor([0.0408, 0.0774, 0.0365, 0.0950, 0.1626, 0.2836, 0.3041])\n"
     ]
    },
    {
     "data": {
      "text/plain": "<pandas.io.formats.style.Styler at 0x7f9530e54ac8>",
      "text/html": "<style  type=\"text/css\" >\n#T_3f62303e_a008_11eb_b4b2_3863bba95829row0_col0{\n            background-color:  #fff9f9;\n        }#T_3f62303e_a008_11eb_b4b2_3863bba95829row0_col1{\n            background-color:  #fff5f5;\n        }#T_3f62303e_a008_11eb_b4b2_3863bba95829row0_col2{\n            background-color:  #fff1f1;\n        }#T_3f62303e_a008_11eb_b4b2_3863bba95829row0_col3{\n            background-color:  #ffc9c9;\n        }#T_3f62303e_a008_11eb_b4b2_3863bba95829row0_col4{\n            background-color:  #ff5656;\n        }</style><table id=\"T_3f62303e_a008_11eb_b4b2_3863bba95829\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >0</th>        <th class=\"col_heading level0 col1\" >1</th>        <th class=\"col_heading level0 col2\" >2</th>        <th class=\"col_heading level0 col3\" >3</th>        <th class=\"col_heading level0 col4\" >4</th>    </tr></thead><tbody>\n                <tr>\n                        <th id=\"T_3f62303e_a008_11eb_b4b2_3863bba95829level0_row0\" class=\"row_heading level0 row0\" >0</th>\n                        <td id=\"T_3f62303e_a008_11eb_b4b2_3863bba95829row0_col0\" class=\"data row0 col0\" >The</td>\n                        <td id=\"T_3f62303e_a008_11eb_b4b2_3863bba95829row0_col1\" class=\"data row0 col1\" >laptop</td>\n                        <td id=\"T_3f62303e_a008_11eb_b4b2_3863bba95829row0_col2\" class=\"data row0 col2\" >runs</td>\n                        <td id=\"T_3f62303e_a008_11eb_b4b2_3863bba95829row0_col3\" class=\"data row0 col3\" >very</td>\n                        <td id=\"T_3f62303e_a008_11eb_b4b2_3863bba95829row0_col4\" class=\"data row0 col4\" >fast</td>\n            </tr>\n    </tbody></table>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<pandas.io.formats.style.Styler at 0x7f9530e54208>",
      "text/html": "<style  type=\"text/css\" >\n#T_3f62303f_a008_11eb_b4b2_3863bba95829row0_col0{\n            background-color:  #fff5f5;\n        }#T_3f62303f_a008_11eb_b4b2_3863bba95829row0_col1{\n            background-color:  #ffecec;\n        }#T_3f62303f_a008_11eb_b4b2_3863bba95829row0_col2{\n            background-color:  #fff6f6;\n        }#T_3f62303f_a008_11eb_b4b2_3863bba95829row0_col3{\n            background-color:  #ffe7e7;\n        }#T_3f62303f_a008_11eb_b4b2_3863bba95829row0_col4{\n            background-color:  #ffd6d6;\n        }#T_3f62303f_a008_11eb_b4b2_3863bba95829row0_col5{\n            background-color:  #ffb7b7;\n        }#T_3f62303f_a008_11eb_b4b2_3863bba95829row0_col6{\n            background-color:  #ffb2b2;\n        }</style><table id=\"T_3f62303f_a008_11eb_b4b2_3863bba95829\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >0</th>        <th class=\"col_heading level0 col1\" >1</th>        <th class=\"col_heading level0 col2\" >2</th>        <th class=\"col_heading level0 col3\" >3</th>        <th class=\"col_heading level0 col4\" >4</th>        <th class=\"col_heading level0 col5\" >5</th>        <th class=\"col_heading level0 col6\" >6</th>    </tr></thead><tbody>\n                <tr>\n                        <th id=\"T_3f62303f_a008_11eb_b4b2_3863bba95829level0_row0\" class=\"row_heading level0 row0\" >0</th>\n                        <td id=\"T_3f62303f_a008_11eb_b4b2_3863bba95829row0_col0\" class=\"data row0 col0\" >I</td>\n                        <td id=\"T_3f62303f_a008_11eb_b4b2_3863bba95829row0_col1\" class=\"data row0 col1\" >am</td>\n                        <td id=\"T_3f62303f_a008_11eb_b4b2_3863bba95829row0_col2\" class=\"data row0 col2\" >fed</td>\n                        <td id=\"T_3f62303f_a008_11eb_b4b2_3863bba95829row0_col3\" class=\"data row0 col3\" >up</td>\n                        <td id=\"T_3f62303f_a008_11eb_b4b2_3863bba95829row0_col4\" class=\"data row0 col4\" >up</td>\n                        <td id=\"T_3f62303f_a008_11eb_b4b2_3863bba95829row0_col5\" class=\"data row0 col5\" >with</td>\n                        <td id=\"T_3f62303f_a008_11eb_b4b2_3863bba95829row0_col6\" class=\"data row0 col6\" >os</td>\n            </tr>\n    </tbody></table>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from data_utils import build_tokenizer, build_embedding_matrix, Tokenizer4Bert, pad_and_truncate\n",
    "from models import IAN\n",
    "\n",
    "\n",
    "from dependency_graph import dependency_adj_matrix\n",
    "\n",
    "from transformers import BertModel\n",
    "\n",
    "model_output = None\n",
    "\n",
    "class CharVal(object):\n",
    "    def __init__(self, char, val):\n",
    "        self.char = char\n",
    "        self.val = val\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.char\n",
    "\n",
    "def rgb_to_hex(rgb):\n",
    "    return '#%02x%02x%02x' % rgb\n",
    "def color_charvals(s):\n",
    "    r = 255-int(s.val*255)\n",
    "    color = rgb_to_hex((255, r, r))\n",
    "    return 'background-color: %s' % color\n",
    "\n",
    "\n",
    "# before the prediction i supposed you tokenized text\n",
    "# you need to match each char and attention\n",
    "\n",
    "\n",
    "def model_hook(module, input_, output):\n",
    "    global model_output\n",
    "    model_output = output\n",
    "\n",
    "class Inferer:\n",
    "    \"\"\"A simple inference example\"\"\"\n",
    "    def __init__(self, opt):\n",
    "        self.opt = opt\n",
    "        if 'bert' in opt.model_name:\n",
    "            self.tokenizer = Tokenizer4Bert(opt.max_seq_len, opt.pretrained_bert_name)\n",
    "            bert = BertModel.from_pretrained(opt.pretrained_bert_name)\n",
    "            self.model = opt.model_class(bert, opt).to(opt.device)\n",
    "        else:\n",
    "            self.tokenizer = build_tokenizer(\n",
    "                fnames=[opt.dataset_file['train'], opt.dataset_file['test']],\n",
    "                max_seq_len=opt.max_seq_len,\n",
    "                dat_fname='{0}_tokenizer.dat'.format(opt.dataset))\n",
    "            embedding_matrix = build_embedding_matrix(\n",
    "                word2idx=self.tokenizer.word2idx,\n",
    "                embed_dim=opt.embed_dim,\n",
    "                dat_fname='{0}_{1}_embedding_matrix.dat'.format(str(opt.embed_dim), opt.dataset))\n",
    "            self.model = opt.model_class(embedding_matrix, opt)\n",
    "        print('loading model {0} ...'.format(opt.model_name))\n",
    "        self.model.load_state_dict(torch.load(opt.state_dict_path))\n",
    "        self.model = self.model.to(opt.device)\n",
    "        # switch model to evaluation mode\n",
    "        self.model.eval()\n",
    "        print(self.model)\n",
    "        torch.autograd.set_grad_enabled(False)\n",
    "\n",
    "    def evaluate(self, text, aspect):\n",
    "        aspect = aspect.lower().strip()\n",
    "        text_left, _, text_right = [s.strip() for s in text.lower().partition(aspect)]\n",
    "\n",
    "        text_indices = self.tokenizer.text_to_sequence(text_left + \" \" + aspect + \" \" + text_right)\n",
    "        context_indices = self.tokenizer.text_to_sequence(text_left + \" \" + text_right)\n",
    "        left_indices = self.tokenizer.text_to_sequence(text_left)\n",
    "        left_with_aspect_indices = self.tokenizer.text_to_sequence(text_left + \" \" + aspect)\n",
    "        right_indices = self.tokenizer.text_to_sequence(text_right, reverse=True)\n",
    "        right_with_aspect_indices = self.tokenizer.text_to_sequence(aspect + \" \" + text_right, reverse=True)\n",
    "        aspect_indices = self.tokenizer.text_to_sequence(aspect)\n",
    "        left_len = np.sum(left_indices != 0)\n",
    "        aspect_len = np.sum(aspect_indices != 0)\n",
    "        aspect_boundary = np.asarray([left_len, left_len + aspect_len - 1], dtype=np.int64)\n",
    "\n",
    "        text_len = np.sum(text_indices != 0)\n",
    "        concat_bert_indices = self.tokenizer.text_to_sequence('[CLS] ' + text_left + \" \" + aspect + \" \" + text_right + ' [SEP] ' + aspect + \" [SEP]\")\n",
    "        concat_segments_indices = [0] * (text_len + 2) + [1] * (aspect_len + 1)\n",
    "        concat_segments_indices = pad_and_truncate(concat_segments_indices, self.tokenizer.max_seq_len)\n",
    "\n",
    "        text_bert_indices = self.tokenizer.text_to_sequence(\"[CLS] \" + text_left + \" \" + aspect + \" \" + text_right + \" [SEP]\")\n",
    "        aspect_bert_indices = self.tokenizer.text_to_sequence(\"[CLS] \" + aspect + \" [SEP]\")\n",
    "\n",
    "        dependency_graph = dependency_adj_matrix(text)\n",
    "\n",
    "        data = {\n",
    "            'concat_bert_indices': concat_bert_indices,\n",
    "            'concat_segments_indices': concat_segments_indices,\n",
    "            'text_bert_indices': text_bert_indices,\n",
    "            'aspect_bert_indices': aspect_bert_indices,\n",
    "            'text_indices': text_indices,\n",
    "            'context_indices': context_indices,\n",
    "            'left_indices': left_indices,\n",
    "            'left_with_aspect_indices': left_with_aspect_indices,\n",
    "            'right_indices': right_indices,\n",
    "            'right_with_aspect_indices': right_with_aspect_indices,\n",
    "            'aspect_indices': aspect_indices,\n",
    "            'aspect_boundary': aspect_boundary,\n",
    "            'dependency_graph': dependency_graph,\n",
    "        }\n",
    "\n",
    "        t_inputs = [torch.tensor([data[col]], device=self.opt.device) for col in self.opt.inputs_cols]\n",
    "        self.model.attention_context.register_forward_hook(model_hook)\n",
    "        t_outputs = self.model(t_inputs)\n",
    "        t_probs = F.softmax(t_outputs, dim=-1).cpu().numpy()\n",
    "\n",
    "        return t_probs\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dataset_files = {\n",
    "        'restaurant': {\n",
    "            'train': './datasets/semeval14/Restaurants_Train.xml.seg',\n",
    "            'test': './datasets/semeval14/Restaurants_Test_Gold.xml.seg'\n",
    "        },\n",
    "        'laptop': {\n",
    "            'train': './datasets/semeval14/Laptops_Train.xml.seg',\n",
    "            'test': './datasets/semeval14/Laptops_Test_Gold.xml.seg'\n",
    "        }\n",
    "    }\n",
    "    class Option(object): pass\n",
    "    opt = Option()\n",
    "    opt.model_name = 'ian'\n",
    "    opt.model_class = IAN\n",
    "    opt.dataset = 'laptop'\n",
    "    opt.dataset_file = dataset_files[\"laptop\"]\n",
    "    opt.inputs_cols = ['text_indices', 'aspect_indices']\n",
    "    # set your trained models here\n",
    "    opt.state_dict_path = 'state_dict/ian_laptop_val_acc_0.6426'\n",
    "    opt.embed_dim = 300\n",
    "    opt.hidden_dim = 300\n",
    "    opt.max_seq_len = 85\n",
    "    opt.bert_dim = 768\n",
    "    opt.pretrained_bert_name = 'bert-base-uncased'\n",
    "    opt.polarities_dim = 3\n",
    "    opt.hops = 3\n",
    "    opt.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    opt.local_context_focus = 'cdm'\n",
    "    opt.SRD = 3\n",
    "\n",
    "    inf = Inferer(opt)\n",
    "    sentence_r = ['I did not like the food, but service was good.',\n",
    "                \"The food was pathetic\",\n",
    "                \"They have very good icecream\"]\n",
    "    sentence_l = [\"The laptop runs very fast\",\n",
    "                \"I am fed up up with os\"]\n",
    "    aspect_r = [\"food\",\"food\",\"icecream\"]\n",
    "    aspect_l = [\"laptop\", \"os\"]\n",
    "    for s, a in zip(sentence_l, aspect_l):\n",
    "        t_probs = inf.evaluate(s, a)\n",
    "        print(t_probs.argmax(axis=-1) - 1)\n",
    "        print(model_output[1].squeeze().cpu())\n",
    "        char_vals = [CharVal(c, v) for c, v in zip(s.split(), model_output[1].squeeze().cpu())]\n",
    "        char_df = pd.DataFrame(char_vals).transpose()\n",
    "        # apply coloring values\n",
    "        char_df = char_df.style.applymap(color_charvals)\n",
    "        display(char_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}